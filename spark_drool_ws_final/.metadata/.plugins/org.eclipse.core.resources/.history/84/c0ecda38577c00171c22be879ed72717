package dynamic;

import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Hashtable;
import java.util.List;
import java.util.Map;

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SQLContext;
import org.apache.spark.sql.SparkSession;
import org.json.simple.JSONArray;
import org.json.simple.JSONObject;
import org.json.simple.parser.JSONParser;
import org.json.simple.parser.ParseException;

public class SparkRuleEngine 
{
	public static void main(String args[])
	{
		SparkSession spark = SparkSession.builder().master("local")
				.appName("Rule Engine")
				.config("spark.some.config.option", "some-value").getOrCreate();
		
		String payload = nodeRedJSONInput();
		
		System.out.println("HHHHHHHHHHHHH");
		System.out.println(payload);
		
		int nodeRedTemp = Integer.parseInt(payload);
		
		
		OrderEvent orderEvent = new OrderEvent();
        //orderEvent.setTemperature(nodeRedTemp); SET INPUT LOG TEMPERATURE

        Rule highValueOrderWidgetsIncRule = new Rule();

        Condition highValueOrderCondition = new Condition();
        highValueOrderCondition.setField("temperature");
        highValueOrderCondition.setOperator(Condition.Operator.GREATER_THAN);
        highValueOrderCondition.setValue(nodeRedTemp);

        highValueOrderWidgetsIncRule.setEventType(Rule.eventType.ORDER);
        highValueOrderWidgetsIncRule.setConditions(Arrays.asList(highValueOrderCondition));

		String drl = applyRuleTemplate(orderEvent, highValueOrderWidgetsIncRule); // RULE  TEMPLATE
																					
		AlertDecision alertDecision = evaluate(drl, orderEvent);

		System.out.println(alertDecision.getDoAlert());

		// doAlert is false by default
		if (alertDecision.getDoAlert()) {
			// do notification
		}
		
		
		
		
		
		
		
		
		
		
		
		
		Dataset<Row> df1 = spark.read().json("/home/neil/.node-red/flows_neil-inspiron-3521.json");
		
		df1.show();
		df1.printSchema();
		df1.select("LOG_ID").show();
		
		df1.createOrReplaceTempView("data1");
	/*
		Dataset<Row> temp3 = spark.sql("SELECT * from data1 where LOG_ID="+i);
		
		DroolTest dt = new DroolTest();
		List<HashMap> update = dt.droolProcess(temp3, temp4, tempPosition.get(i), presPos.get(i), gasPos.get(i));
		
		updateJSON(spark, i, df1, df2, update);*/
	}

	private static void updateJSON(SparkSession spark, int i, Dataset<Row> df1,
			Dataset<Row> df2, List<HashMap> updates) 
	{
		if(!updates.isEmpty())
		{
			HashMap<String, Integer> h1 = (HashMap<String, Integer>)updates.get(0);
			HashMap<String, Double> h2 = (HashMap<String, Double>) updates.get(1);
			
			System.out.println("temperature 1 updated : "+ h1.get("TEMP1"));
			System.out.println("temperature 2 updated : "+ h1.get("TEMP2"));
			
			System.out.println("pressure 1 updated : "+ h1.get("PRE1"));
			System.out.println("pressure 2 updated : "+ h1.get("PRE2"));
			
			System.out.println("gas 1 updated : "+ h2.get("GAS1"));
			System.out.println("gas 2 updated : "+ h2.get("GAS2"));
			
			df1.registerTempTable("citytemps1");
			df2.registerTempTable("citytemps2");
			
			allUDFs(spark, h1, h2);
			
			SQLContext sq7 = new SQLContext(spark);
			Dataset<Row> b1 = sq7.sql("SELECT LOG_ID, CHANGE_PRE1(0) AS PRESSURE, GAS, CHANGE_TEMP1(0) AS TEMPERATURE FROM citytemps1 where LOG_ID="+i);
			Dataset<Row> b2 = sq7.sql("SELECT LOG_ID, CHANGE_PRE2(0) AS PRESSURE, GAS, CHANGE_TEMP2(0) AS TEMPERATURE FROM citytemps2 where LOG_ID="+(i+1));
			System.out.println(b1.head());
			System.out.println(b2.head());

			b1.write().json("/home/neil/Neil_Work/MS_SJSU/scala_spark_learning/Spark_Scala/git_ws/SparkDrools/loglog"+i);
			b2.write().json("/home/neil/Neil_Work/MS_SJSU/scala_spark_learning/Spark_Scala/git_ws/SparkDrools/loglog"+(i+1));
		}
	}

	private static void allUDFs(SparkSession spark,
			HashMap<String, Integer> h1, HashMap<String, Double> h2) 
	{
		// FUNCTIONS
		
	}

	 static private AlertDecision evaluate(String drl, Event event) throws Exception {
	        KieServices kieServices = KieServices.Factory.get();
	        KieFileSystem kieFileSystem = kieServices.newKieFileSystem();
	        kieFileSystem.write("src/main/resources/rule.drl", drl);
	        kieServices.newKieBuilder(kieFileSystem).buildAll();

	        KieContainer kieContainer = kieServices.newKieContainer(kieServices.getRepository().getDefaultReleaseId());
	        StatelessKieSession statelessKieSession = kieContainer.getKieBase().newStatelessKieSession();

	        AlertDecision alertDecision = new AlertDecision();
	        statelessKieSession.getGlobals().set("alertDecision", alertDecision);
	        statelessKieSession.execute(event);

	        return alertDecision;
	    }

	    static private String applyRuleTemplate(OrderEvent event, Rule rule) throws Exception {
	        Map<String, Object> data = new HashMap<String, Object>();
	        ObjectDataCompiler objectDataCompiler = new ObjectDataCompiler();

	        data.put("rule", rule); // Check rule-template.drl : Map refers in .drl file
	        data.put("eventType", event.getClass().getName());
	        
	        InputStream is = ClassLoader.getSystemClassLoader().getResourceAsStream("com/rules/rule-template.drl");
	        return objectDataCompiler.compile(Arrays.asList(data), is);
	    }
	
	private static String nodeRedJSONInput() 
	{
		String payload = null;
		try
		{
			JSONParser parser = new JSONParser();
			JSONArray jArray = (JSONArray) parser
					.parse(new FileReader(
							"/home/neil/.node-red/flows_neil-inspiron-3521.json"));
		
			for (Object obj : jArray) 
			{
				JSONObject jsonObject = (JSONObject) obj;
				System.out.println(jsonObject);
		
				String id = (String) jsonObject.get("id");
				if(!id.equals("4f47f2a.261f50c") && !id.equals("bec3915b.0ca4f"))
				{
					String topic = (String) jsonObject.get("topic");
					System.out.println(topic);
		
					payload = (String) jsonObject.get("payload");
					System.out.println(payload);
				}
			}
		}
		catch(Exception e)
		{
			System.out.println("NODE RED JSON : ");
			e.printStackTrace();
		}
		return payload;
	}
}
